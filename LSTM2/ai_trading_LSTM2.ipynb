{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://qiita.com/tizuo/items/b9af70e8cdc7fb69397f\n",
    "# https://www.codexa.net/keras-lstm-cryptos-forecast/\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import math\n",
    "\n",
    "from pandas.core import resample\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Dropout\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.callbacks import EarlyStopping, CSVLogger\n",
    "\n",
    "from pylab import rcParams\n",
    "%matplotlib inline\n",
    "\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_output_columns = 5\n",
    "look_back = 7\n",
    "\n",
    "#column=[ 'Close','High','Low','HighLowDiff','OpenRelativePosition','CloseRelativePosition','ADXadx','RCIs']\n",
    "\n",
    "column=[ 'Close','High','Low','Open','ADXadx','HighLowDiff','OpenRelativePosition','CloseRelativePosition']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 為替予測\n",
    "\n",
    "#filename = '~/Documents/ML/tensorflow/csv/GBPJPY_M15.csv'\n",
    "filename = './csv/3CUR_IND/EU60.csv'\n",
    "\n",
    "# \n",
    "df = pd.read_csv(filename,\n",
    "#                nrows=100000,\n",
    "                usecols=['Date','Week',\n",
    "                        'Open','High','Low','Close','Volume','Profit','HighLowDiff','OpenRelativePosition','CloseRelativePosition',\n",
    "                        'RCIs','RCIm','RCIl','ADXdm','ADXdp','ADXadx','MACD','MACDsig','Stocha','StochaSig'],\n",
    "                dtype={ 'Date': str,\n",
    "                        'Week':float,\n",
    "                        'Open':float,'High':float,'Low':float,'Close':float,'Volume':float,'Profit':float,\n",
    "                        'HighLowDiff':float,'OpenRelativePosition':float,'CloseRelativePosition':float,\n",
    "                        'RCIs':float,'RCIm':float,'RCIl':float,'ADXdm':float,'ADXdp':float,'ADXadx':float,\n",
    "                       'MACD':float,'MACDsig':float,'Stocha':float,'StochaSig':float},\n",
    "                parse_dates=[0]\n",
    "            ).sort_values(by='Date', ascending=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52496\n"
     ]
    }
   ],
   "source": [
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 日付と時間のデータが分かれているので、一つにつなげて日時型に変換し、インデックスに指定\n",
    "#df['Datetime'] = pd.to_datetime(df['Date']+' '+df['Time'])\n",
    "\n",
    "df.index = df['Date']\n",
    "df = df[df.index.year>=2010]\n",
    "df.sort_index(ascending=True)\n",
    "\n",
    "df.dropna(inplace=True) #2つ以上のNanは削除。inplaceは自身を書き換え\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 52491 entries, 2010-01-04 00:00:00 to 2018-07-18 09:00:00\n",
      "Data columns (total 21 columns):\n",
      "Date                     52491 non-null datetime64[ns]\n",
      "Week                     52491 non-null float64\n",
      "Open                     52491 non-null float64\n",
      "High                     52491 non-null float64\n",
      "Low                      52491 non-null float64\n",
      "Close                    52491 non-null float64\n",
      "Volume                   52491 non-null float64\n",
      "Profit                   52491 non-null float64\n",
      "HighLowDiff              52491 non-null float64\n",
      "OpenRelativePosition     52491 non-null float64\n",
      "CloseRelativePosition    52491 non-null float64\n",
      "RCIs                     52491 non-null float64\n",
      "RCIm                     52491 non-null float64\n",
      "RCIl                     52491 non-null float64\n",
      "ADXdm                    52491 non-null float64\n",
      "ADXdp                    52491 non-null float64\n",
      "ADXadx                   52491 non-null float64\n",
      "MACD                     52491 non-null float64\n",
      "MACDsig                  52491 non-null float64\n",
      "Stocha                   52491 non-null float64\n",
      "StochaSig                52491 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(20)\n",
      "memory usage: 8.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#df['Week']=df['Week'].astype('float32')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(df.info())\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        xset = []\n",
    "        for j in range(dataset.shape[1]):\n",
    "            a = dataset[i:(i+look_back), j]\n",
    "            xset.append(a)\n",
    "        dataY.append(dataset[i + look_back, ])      \n",
    "        dataX.append(xset)\n",
    "    return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Close     High      Low     Open     ADXadx  \\\n",
      "Date                                                                 \n",
      "2010-01-04 00:00:00  1.43156  1.43336  1.43151  1.43259  33.783064   \n",
      "2010-01-04 01:00:00  1.42886  1.43195  1.42879  1.43156  37.266355   \n",
      "2010-01-04 02:00:00  1.42705  1.42885  1.42569  1.42885  41.802726   \n",
      "2010-01-04 03:00:00  1.42947  1.42989  1.42700  1.42702  43.277511   \n",
      "2010-01-04 04:00:00  1.42848  1.42968  1.42718  1.42945  44.555657   \n",
      "\n",
      "                     HighLowDiff  OpenRelativePosition  CloseRelativePosition  \n",
      "Date                                                                           \n",
      "2010-01-04 00:00:00      0.00185              0.167568              -0.945946  \n",
      "2010-01-04 01:00:00      0.00316              0.753165              -0.955696  \n",
      "2010-01-04 02:00:00      0.00316              1.000000              -0.139241  \n",
      "2010-01-04 03:00:00      0.00289             -0.986159               0.709343  \n",
      "2010-01-04 04:00:00      0.00250              0.816000               0.040000  \n"
     ]
    }
   ],
   "source": [
    "# Yは最初の列に配置\n",
    "#dataframe = df.loc[:,['Close','High','Low','Volume','HighLowDiff','OpenRelativePosition','CloseRelativePosition','Week','Hourminutes']].dropna()\n",
    "\n",
    "#dataframe = df.loc[:,[ 'Open','High','Low','Close','ADXadx','Stocha','StochaSig','HighLowDiff','OpenRelativePosition','CloseRelativePosition']].dropna()\n",
    "\n",
    "\n",
    "dataframe = df.loc[:,column].dropna()\n",
    "\n",
    "\n",
    "#dataframe = df.loc[:,['ExpectedPrice','Close',]].dropna()\n",
    "\n",
    "print(dataframe[:5])   #  一番左にDateが出るがIndexであるため無視して良い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "41992 10499\n"
     ]
    }
   ],
   "source": [
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float64')\n",
    "#dataset = dataset.astype('str')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# データを標準化します。LSTMはセンシティブなので扱う数値を標準化されなければならない\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "print(scaler)\n",
    "\n",
    "# データのうちの0.2をテスト用\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41984, 8, 7)\n",
      "(41984, 8)\n",
      "(10491, 8, 7)\n",
      "(10491, 8)\n",
      "------\n",
      "[[ 0.86091384  0.86222067  0.86309172  0.86206897  0.42541536  0.11455847\n",
      "   0.7034485   0.527586  ]\n",
      " [ 0.86281494  0.86173915  0.86063832  0.8609108   0.42073585  0.150358\n",
      "   0.6921055   0.926316  ]\n",
      " [ 0.86958897  0.86865548  0.86745088  0.86281194  0.35161623  0.15234686\n",
      "   0.1012985   0.9116885 ]\n",
      " [ 0.88248148  0.88104358  0.87529298  0.8698702   0.33663456  0.23508353\n",
      "   0.0067455   0.9831365 ]\n",
      " [ 0.87841706  0.88200661  0.88370463  0.88252262  0.33054645  0.09984089\n",
      "   0.7865615   0.0513835 ]\n",
      " [ 0.88152001  0.88568364  0.88387987  0.8783707   0.34068875  0.16348449\n",
      "   0.0024215   0.355932  ]]\n",
      "8\n",
      "(41984, 8, 7)\n",
      "(41984, 8)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "\n",
    "print(testX.shape)\n",
    "print(testY.shape)\n",
    "\n",
    "#print(trainX[:6]) \n",
    "print('------')\n",
    "print(trainY[:6]) \n",
    "\n",
    "print(trainY.shape[1])\n",
    "\n",
    "trainY_tmp=np.delete(trainY,range(input_output_columns,trainY.shape[1]),1)\n",
    "testY_tmp=np.delete(testY,range(input_output_columns,testY.shape[1]),1)\n",
    "\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "\n",
    "trainY=trainY_tmp\n",
    "testY=testY_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41984 samples, validate on 10491 samples\n",
      "Epoch 1/500\n",
      " - 12s - loss: 0.0055 - acc: 0.5141 - val_loss: 0.0015 - val_acc: 0.7002\n",
      "Epoch 2/500\n",
      " - 11s - loss: 0.0011 - acc: 0.5922 - val_loss: 5.7661e-04 - val_acc: 0.8111\n",
      "Epoch 3/500\n",
      " - 11s - loss: 5.8795e-04 - acc: 0.6765 - val_loss: 4.7433e-04 - val_acc: 0.6671\n",
      "Epoch 4/500\n",
      " - 13s - loss: 4.5511e-04 - acc: 0.7236 - val_loss: 3.3193e-04 - val_acc: 0.8735\n",
      "Epoch 5/500\n",
      " - 12s - loss: 4.0001e-04 - acc: 0.7498 - val_loss: 4.8498e-04 - val_acc: 0.8501\n",
      "Epoch 6/500\n",
      " - 13s - loss: 3.3120e-04 - acc: 0.7610 - val_loss: 3.2577e-04 - val_acc: 0.8892\n",
      "Epoch 7/500\n",
      " - 11s - loss: 2.9520e-04 - acc: 0.7509 - val_loss: 2.1989e-04 - val_acc: 0.8962\n",
      "Epoch 8/500\n",
      " - 12s - loss: 2.7584e-04 - acc: 0.7586 - val_loss: 2.4846e-04 - val_acc: 0.8616\n",
      "Epoch 9/500\n",
      " - 12s - loss: 2.5603e-04 - acc: 0.7551 - val_loss: 1.9395e-04 - val_acc: 0.8698\n",
      "Epoch 10/500\n",
      " - 11s - loss: 2.3828e-04 - acc: 0.7617 - val_loss: 1.8499e-04 - val_acc: 0.8990\n",
      "Epoch 11/500\n",
      " - 12s - loss: 2.2611e-04 - acc: 0.7589 - val_loss: 1.9057e-04 - val_acc: 0.8974\n",
      "Epoch 12/500\n",
      " - 12s - loss: 2.1701e-04 - acc: 0.7576 - val_loss: 1.7711e-04 - val_acc: 0.6889\n",
      "Epoch 13/500\n",
      " - 10s - loss: 1.9761e-04 - acc: 0.7590 - val_loss: 2.0639e-04 - val_acc: 0.8335\n",
      "Epoch 14/500\n",
      " - 10s - loss: 1.8623e-04 - acc: 0.7593 - val_loss: 1.6734e-04 - val_acc: 0.8993\n",
      "Epoch 15/500\n",
      " - 10s - loss: 1.8351e-04 - acc: 0.7632 - val_loss: 1.5533e-04 - val_acc: 0.8961\n",
      "Epoch 16/500\n",
      " - 10s - loss: 1.7201e-04 - acc: 0.7638 - val_loss: 2.0040e-04 - val_acc: 0.9036\n",
      "Epoch 17/500\n",
      " - 10s - loss: 1.6691e-04 - acc: 0.7628 - val_loss: 1.4412e-04 - val_acc: 0.8870\n",
      "Epoch 18/500\n",
      " - 11s - loss: 1.6612e-04 - acc: 0.7565 - val_loss: 1.4610e-04 - val_acc: 0.8980\n",
      "Epoch 19/500\n",
      " - 10s - loss: 1.5253e-04 - acc: 0.7569 - val_loss: 1.4039e-04 - val_acc: 0.7044\n",
      "Epoch 20/500\n",
      " - 10s - loss: 1.5791e-04 - acc: 0.7411 - val_loss: 1.4217e-04 - val_acc: 0.8868\n",
      "Epoch 21/500\n",
      " - 12s - loss: 1.4840e-04 - acc: 0.7406 - val_loss: 1.3824e-04 - val_acc: 0.9052\n",
      "Epoch 22/500\n",
      " - 10s - loss: 1.4630e-04 - acc: 0.7373 - val_loss: 1.4361e-04 - val_acc: 0.8984\n",
      "Epoch 23/500\n",
      " - 11s - loss: 1.4258e-04 - acc: 0.7419 - val_loss: 1.5417e-04 - val_acc: 0.9067\n",
      "Epoch 24/500\n",
      " - 11s - loss: 1.3932e-04 - acc: 0.7225 - val_loss: 1.7067e-04 - val_acc: 0.6482\n",
      "Epoch 25/500\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=40, verbose=1) \n",
    "\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(testX.shape[1], look_back)))\n",
    "    \n",
    "model.add(Dense(input_output_columns))\n",
    "\n",
    "model.add(Activation(\"hard_sigmoid\"))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])\n",
    "model_history=model.fit(trainX, trainY, epochs=500, batch_size=64, verbose=2, validation_data=(testX,testY),callbacks=[early_stopping])\n",
    "#model_history=model.fit(trainX, trainY, epochs=500, batch_size=32, verbose=2, validation_data=(testX,testY))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのsave/load\n",
    "import pickle\n",
    "model.save('model.h5')\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    \n",
    "score = model.evaluate(testX, testY, verbose=0)\n",
    "print(\"Test score:\" + str(score[0]))\n",
    "print(\"Test accuracy:\" + str(score[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainPredict.shape)\n",
    "print(testPredict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print('trainPredict.shape='+str(trainPredict.shape))\n",
    "print('testPredict.shape='+str(testPredict.shape))\n",
    "print('trainX.shape='+str(trainX.shape))\n",
    "print('trainY.shape='+str(trainY.shape))\n",
    "print('------')\n",
    "print(trainX.shape[1])\n",
    "print('------')\n",
    "\n",
    "\n",
    "train_zero=np.resize(trainX,(trainX.shape[0],trainX.shape[1]))[:,input_output_columns:]  # scaler実行時のrow/column-1 をつくり、そこからinput_output_columnsの右の列を追加\n",
    "train_zero.fill(0)\n",
    "trainPredict = np.hstack([trainPredict,train_zero])\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "\n",
    "trainY = np.hstack([trainY,train_zero])\n",
    "trainY = scaler.inverse_transform(trainY)\n",
    "\n",
    "\n",
    "test_zero=np.resize(testX,(testY.shape[0],testX.shape[1]))[:,input_output_columns:]  # scaler実行時のrow/column-1 をつくり、そこからinput_output_columnsの右の列を追加\n",
    "test_zero.fill(0)\n",
    "\n",
    "testPredict = np.hstack([testPredict,test_zero])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "\n",
    "testY = np.hstack([testY,test_zero])\n",
    "testY = scaler.inverse_transform(testY)\n",
    "\n",
    "print(trainPredict.shape)\n",
    "print(testPredict.shape)\n",
    "\n",
    "\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[:,0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[:,0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "acc = model_history.history['acc']\n",
    "loss = model_history.history['loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = model_history.history['acc']\n",
    "loss = model_history.history['loss']\n",
    "\n",
    "print(acc[-1])\n",
    "print(loss[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testY[:,0])\n",
    "print(testPredict[:,0])\n",
    "\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(dataset)-len(testPredict):len(dataset), :] = testPredict\n",
    "\n",
    "#testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "#testPredictPlot[len(trainPredict)+(look_back*2):len(dataset), :] = testPredict\n",
    "#testPredictPlot[len(trainPredict)+(look_back*2)+2:len(dataset), :] = testPredict\n",
    "\n",
    "\n",
    "plottestY=testY\n",
    "plotpredict=testPredictPlot[len(testPredictPlot)-len(testY)::]\n",
    "\n",
    "# plot baseline and predictions\n",
    "\n",
    "rcParams['figure.figsize'] = 20,10\n",
    "#plt.plot(scaler.inverse_transform(dataset))\n",
    "tra=scaler.inverse_transform(dataset)\n",
    "plt.plot(tra[:,0])\n",
    "plt.plot(trainPredictPlot[:,0])\n",
    "plt.plot(testPredictPlot[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset)-len(testPredict))\n",
    "print(testPredict.shape)\n",
    "print(testPredict[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape)\n",
    "print(testX.shape)\n",
    "\n",
    "print(trainPredict.shape)\n",
    "print(testPredict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1)\n",
    " \n",
    "ax1.plot(model_history.epoch, model_history.history['loss'])\n",
    "ax1.set_title('TrainingError')\n",
    " \n",
    "if model.loss == 'mae':\n",
    "    ax1.set_ylabel('Mean Absolute Error (MAE)',fontsize=12)\n",
    "# もでるおんロス計算を変更した場合のため\n",
    "else:\n",
    "    ax1.set_ylabel('Model Loss',fontsize=12)\n",
    "ax1.set_xlabel('# Epochs',fontsize=12)\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 損失の履歴をプロット\n",
    "plt.clf()\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.legend(['loss', 'val_loss'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# チャート作成(ACC/LOSS)\n",
    "plt.clf()\n",
    "epochs = len(loss)\n",
    "plt.plot(range(epochs), acc, marker='.', label='acc')\n",
    "plt.plot(range(epochs), loss, marker='.', label='loss')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as tick # 目盛り操作に必要なライブラリを読み込みます\n",
    "\n",
    "rcParams['figure.figsize'] = 20,60\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.rcParams['font.family'] ='sans-serif'\n",
    "\n",
    "\n",
    "plotpredict[:,0]=(plotpredict[:,0]+plotpredict[:,1]+plotpredict[:,2])/3 #Typica Price\n",
    "#plotpredict[:,0]=(plotpredict[:,1]+plotpredict[:,2])/2 #Typica Price\n",
    "\n",
    "\n",
    "gs = gridspec.GridSpec(8,1)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.3)\n",
    "\n",
    "plt.subplot(gs[0,0])\n",
    "plt.grid()\n",
    "plt.plot(plottestY[-400:,0],label='actual',linewidth=1.0)\n",
    "plt.plot(plotpredict[-400:,0],label='predict',linewidth=1.0)\n",
    "plt.title('Column:0 400 bar')\n",
    "plt.gca().xaxis.set_minor_locator(tick.MultipleLocator(10))\n",
    "plt.grid(which='minor')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(gs[1,0])\n",
    "plt.grid()\n",
    "plt.plot(plottestY[-100:,0],label='actual',linewidth=1.0)\n",
    "plt.plot(plotpredict[-100:,0],label='predict',linewidth=1.0)\n",
    "plt.title('Column:0 100 bar')\n",
    "plt.gca().xaxis.set_minor_locator(tick.MultipleLocator(1))\n",
    "plt.grid(which='minor')\n",
    "plt.legend()\n",
    "\n",
    "if len(column)>1:\n",
    "    plt.subplot(gs[2,0])\n",
    "    plt.grid()\n",
    "    plt.plot(plottestY[-100:,1],label='actual',linewidth=1.0)\n",
    "    plt.plot(plotpredict[-100:,1],label='predict',linewidth=1.0)\n",
    "    plt.title('Column:1 100  bar')\n",
    "    plt.gca().xaxis.set_minor_locator(tick.MultipleLocator(1))\n",
    "    plt.grid(which='minor')\n",
    "    plt.legend()\n",
    "\n",
    "if len(column)>2:\n",
    "    plt.subplot(gs[3,0])\n",
    "    plt.grid()\n",
    "    plt.plot(plottestY[-100:,2],label='actual',linewidth=1.0)\n",
    "    plt.plot(plotpredict[-100:,2],label='predict',linewidth=1.0)\n",
    "    plt.title('Column:2 100 bar')\n",
    "    plt.gca().xaxis.set_minor_locator(tick.MultipleLocator(1))\n",
    "    plt.grid(which='minor')\n",
    "    plt.legend()\n",
    "\n",
    "if len(column)>3:\n",
    "    plt.subplot(gs[4,0])\n",
    "    plt.grid()\n",
    "    plt.plot(plottestY[-100:,3],label='actual',linewidth=1.0)\n",
    "    plt.plot(plotpredict[-100:,3],label='predict',linewidth=1.0)\n",
    "    plt.title('Column:3 100 bar')\n",
    "    plt.gca().xaxis.set_minor_locator(tick.MultipleLocator(1))\n",
    "    plt.grid(which='minor')\n",
    "    plt.legend()\n",
    "\n",
    "if len(column)>4:\n",
    "    plt.subplot(gs[5,0])\n",
    "    plt.grid()\n",
    "    plt.plot(plottestY[-100:,4],label='actual',linewidth=1.0)\n",
    "    plt.plot(plotpredict[-100:,4],label='predict',linewidth=1.0)\n",
    "    plt.title('Column:4 100 bar')\n",
    "    plt.gca().xaxis.set_minor_locator(tick.MultipleLocator(1))\n",
    "    plt.grid(which='minor')\n",
    "    plt.legend()\n",
    "\n",
    "plt.subplot(gs[6:8:,0])\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(plottestY[-60:,0],color='#b346fc',alpha=1.0,label='0 Actual',linewidth=2.0)\n",
    "plt.plot(plotpredict[-60:,0],color='#b346fc',alpha=0.5,label='0 Predict',linewidth=0.5,marker='o')\n",
    "\n",
    "\n",
    "if len(column)>1:\n",
    "    plt.plot(plottestY[-60:,1],color='#ff033d',alpha=1.0,label='1 Actual',linewidth=2.0)\n",
    "    plt.plot(plotpredict[-60:,1],color='#ff033d',alpha=0.5,label='1 Predict',linewidth=0.5,marker='o')\n",
    "\n",
    "if len(column)>2:\n",
    "    plt.plot(plottestY[-60:,2],color='#0dc4e0',alpha=1.0,label='2 Actual',linewidth=2.0)\n",
    "    plt.plot(plotpredict[-60:,2],color='#0dc4e0',alpha=0.5,label='2 Predict',linewidth=0.5,marker='o')\n",
    "\n",
    "#if len(column)>3:\n",
    "#    plt.plot(plottestY[-30:,3],color='#333333',alpha=0.4,label='3 Actual',linewidth=0.5)\n",
    "#    plt.plot(plotpredict[-30:,3],color='#333333',alpha=1.0,label='3 Predict',linewidth=0.5,marker='.')\n",
    "\n",
    "#                                    plt.plot(plottestY[-30:,4],color='#56f442',alpha=0.4,label='Adx Actual',linewidth=0.5,marker='.')\n",
    "#                                    plt.plot(plotpredict[-30:,4],color='#56f442',alpha=1.0,label='Adx Predict',linewidth=0.5)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('0-3(max) columns')\n",
    "plt.gca().xaxis.set_minor_locator(tick.MultipleLocator(1))\n",
    "plt.grid(which='minor')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_candle = plottestY[-200:,[0,1,2]]\n",
    "#print(df_candle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2,3,4,5,6,7,8,9,10]\n",
    "print(a)\n",
    "print(a[2])\n",
    "print(a[2::]) #offset2からすべて\n",
    "print(a[:2:]) #先頭から2件\n",
    "print(a[::2]) #一個飛ばし\n",
    "print(a[-2:]) #最後の数件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mpl_finance import candlestick_ohlc\n",
    "\n",
    "df_candle_testY = df.loc[:,['Close','High','Low','Open']].dropna()\n",
    "df_candle_testY = df_candle_testY[-800:]\n",
    "\n",
    "df_candle_predictY = pd.DataFrame(plotpredict[-800:,[0,1,2]])\n",
    "df_candle_predictY.columns = ['Close','High','Low']\n",
    "df_candle_predictY['Datetime'] = df_candle_testY.index.values\n",
    "df_candle_predictY.index = df_candle_predictY['Datetime']\n",
    "df_candle_predictY.drop('Datetime',axis=1,inplace=True) \n",
    "\n",
    "df_candle_predictY['Open']=df_candle_testY['Open'].astype('float64')\n",
    "df_candle_predictY['High']=df_candle_predictY['High'].astype('float64')\n",
    "df_candle_predictY['Low']=df_candle_predictY['Low'].astype('float64')\n",
    "df_candle_predictY['Close']=df_candle_predictY['Close'].astype('float64')\n",
    "\n",
    "\n",
    "#print(df_candle_predictY[:5])\n",
    "#print(df_candle_testY.info())\n",
    "#print(df_candle_predictY.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_candle_testY[0:5:])\n",
    "#print(df_candle_testY[-5:])\n",
    "\n",
    "#print(df_candle_predictY[0:5:])\n",
    "#print(df_candle_predictY[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly import figure_factory as FF\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "init_notebook_mode(connected=True) # Jupyter notebook用設定\n",
    "\n",
    "input_candle_bars = -30\n",
    "\n",
    "# create_candlestickのdatesを外すと predicate が表示されなくなる\n",
    "fig = FF.create_candlestick(df_candle_testY.Open[input_candle_bars:], \n",
    "                            df_candle_testY.High[input_candle_bars:], \n",
    "                            df_candle_testY.Low[input_candle_bars:], \n",
    "                            df_candle_testY.Close[input_candle_bars:],\n",
    "                            dates=df_candle_testY.index[input_candle_bars:],\n",
    "                            direction='increasing',\n",
    "                            line=Line(color='rgba(58, 249, 81,0.4)')\n",
    "                           )\n",
    "\n",
    "fig_dec = FF.create_candlestick(df_candle_testY.Open[input_candle_bars:], \n",
    "                            df_candle_testY.High[input_candle_bars:], \n",
    "                            df_candle_testY.Low[input_candle_bars:], \n",
    "                            df_candle_testY.Close[input_candle_bars:],\n",
    "                            dates=df_candle_testY.index[input_candle_bars:],\n",
    "                            direction='decreasing',\n",
    "                            line=Line(color='rgba(232, 101, 97,0.4)')\n",
    "                           )\n",
    "\n",
    "\n",
    "\n",
    "#xtick0 = (5-df.index[0].weekday())%5 #最初の月曜日のインデックス\n",
    "fig['layout'].update({\n",
    "    'xaxis':{\n",
    "        'showgrid': True,\n",
    "#        'ticktext': [x.strftime('%Y-%m-%d %H:00') for x in df.index][xtick0::5],\n",
    "#        'tickvals': np.arange(xtick0,len(df),5)\n",
    "    }\n",
    "})\n",
    "fig['data'].extend(fig_dec['data'])\n",
    "add_line = [\n",
    "            go.Scatter(x=df_candle_predictY.index[input_candle_bars:], y=df_candle_predictY['High'][input_candle_bars:], name='p_high', line=Line(color = 'rgba(244, 65, 65, 1.0)',width=1)),\n",
    "            go.Scatter(x=df_candle_predictY.index[input_candle_bars:], y=df_candle_predictY['Close'][input_candle_bars:], name='p_close', line=Line(color = 'rgba(90, 90, 90, 1.0)',width=1)),\n",
    "            go.Scatter(x=df_candle_predictY.index[input_candle_bars:], y=df_candle_predictY['Low'][input_candle_bars:], name='p_low', line=Line(color = 'rgba(65, 76, 244, 1.0)',width=1)),\n",
    "           ]\n",
    "#fig['layout'].update({'xaxis':{'showgrid': True}})\n",
    "\n",
    "fig['data'].extend(add_line)\n",
    "py.offline.iplot(fig)#,filename='figure.html', image='png', auto_open=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
